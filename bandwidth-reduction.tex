\chapter{Application-Agnostic Techniques to Reduce Network Transmission}
\label{chapter: bandwidth}

WCAs continuously stream sensor data to a cloudlet. The richer a sensing
modality is, the more information can be extracted. The core sensing modality of
WCAs is visual data, e.g. egocentric images and videos from wearable cameras.
Compared to other sensors, e.g. microphones and inertial measurement units
(IMUs), cameras capture visual information with rich semantics. As commercial
camera hardware become more affordable, they have become increasingly pervasive.
In 2013, it is estimated that there is one security camera for every eleven
citizens in the UK~\cite{Barrett2013}. In the meantime, deep neural networks
(DNNs) have driven significant advancement in computer vision and have achieved
human-level accuracy in several previously intractable perception problems (e.g.
face recognition, image classification)~\cite{learned2016labeled,
    schroff2015facenet}. The richness and the open-endness of visual data makes
camera the ideal sensor for WCAs.

However, continuous video transmission from many Tier-3 devices places severe
stress on the wireless spectrum.  Hulu estimates that its video streams require
13 Mbps for 4K resolution and 6 Mbps for HD resolution using highly optimized
offline encoding~\cite{Hulu2017}. Live streaming is less bandwidth-efficient, as
confirmed by our measured bandwidth of 10 Mbps for HD feed at 25 FPS. Just 50
users transmitting HD video streams continuously can saturate the theoretical
uplink capacity of 500 Mbps in a 4G LTE cell that covers a large rural
area~\cite{LteWorld2009}.  This is clearly not scalable.

In this chapter, we show how per-user bandwidth demand in WCA-like live video
analytics can be significantly reduced using an application-agnostic approach.
We aim to reduce bandwidth demand without compromising the timeliness or
accuracy of results. In contrast to previous
works~\cite{Wang2017networked,zhang2015design,Wang2016skyeyes}, we leverage
state-of-the-art deep neural networks (DNNs) to selectively transmit interesting
data from a video stream and explore environment-specific optimizations. The
accuracy of the data selection is important, as fewer false positives result in
lower network bandwidth and cloudlet computing cycle consumption.

This chapter is organized as follows. We first discuss the challenges of running
DNNs for visual perception solely on Tier-3 devices in
Section~\ref{bw:challenges}. Next, we propose and compare two
application-agnostic techniques to reduce network transmission. We present our
results first in the context of live video analytics for small autonomous
drones. Both as emerging Tier-3 devices, drones and wearable devices face
similar challenges in live video analysis. Finally, we showcase how these
techniques can be applied to WCAs in Section~\ref{bw:wca}.

\input{bandwidth-reduction-challenges}
\input{bandwidth-reduction-dumbdrone}
\input{bandwidth-reduction-earlydiscard}
\input{bandwidth-reduction-jitl}
\input{bandwidth-reduction-wca}
\input{bandwidth-reduction-related}