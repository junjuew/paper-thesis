\chapter{Application-Agnostic Techniques to Reduce Network Transmission}
\label{chapter: bandwidth}

WCAs continuously stream sensor data to the cloudlet. The richer a sensing
modality is, the more information can be extracted. The core sensing modality of
WCAs is visual data, e.g. first-person view images and videos from wearable
cameras. Compared to other sensors, e.g. microphones and inertial measurement
units (IMUs), cameras capture deep semantic information. With the fast
decreasing costs of camera hardware, they become increasingly pervasive in
recent years. In the meantime, significant advancement in computer driven by
deep neural networks (DNNs) has made many previously difficult perception
problems tractable. The richness and open-endness of visual data makes camera
the core sensor of WCAs.

However, continuous video transmission from many Tier-3 devices places severe
stress on the wireless spectrum.  Hulu estimates that its video streams require
13 Mbps for 4K resolution and 6 Mbps for HD resolution using highly optimized
offline encoding~\cite{Hulu2017}. Live streaming is less bandwidth-efficient, as
confirmed by our measured bandwidth of 10 Mbps for HD feed at 25 FPS. Just 50
users transmitting HD video streams continuously can saturate the theoretical
uplink capacity of 500 Mbps in a 4G LTE cell that covers a large rural
area~\cite{LteWorld2009}.  This is clearly not scalable.

In this chapter, we show how per-user bandwidth demand in live video analytics
can be significantly reduced using an application-agnostic approach. We aim to
reduce bandwidth demand without compromising the timeliness or accuracy of
results. We present techniques for an adaptive computer vision pipeline for
Tier-3 devices that leverages edge computing to enable dynamic optimizations. In
contrast to previous
works~\cite{Wang2017networked}~\cite{zhang2015design}~\cite{Wang2016skyeyes}, we
leverage state-of-the-art deep neural networks (DNNs) to selectively transmit
interesting data from a video stream and explore mission-specific optimizations.
We present results first in the context of live video analytics for drones. As
exemplars of Tier-3 devices, drones and wearable devices face similar challenges
in live video analysis. Then, we showcase how these techniques can be applied to
WCAs.

\input{bandwidth-reduction-challenges}
\input{bandwidth-reduction-dumbdrone}
\input{bandwidth-reduction-earlydiscard}
\input{bandwidth-reduction-jitl}
\input{bandwidth-reduction-wca}