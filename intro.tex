\chapter{Introduction}
\label{chapter: intro}

It has been a long endeavour to augment human cognition with machine
intelligence. As early as in 1945, Vannevar Bush envisioned a machine Memex that
provides "enlarged intimate supplement to one's memory" and can be "consulted
with exceeding speed and flexibility" in the seminal article \textit{As We May
Think}~\cite{bush1945we}. This vision has been brought closer to reality by
years of research in computing hardware, artificial intelligence, and
human-computer interaction. In late 90s to early 2000s, Smailagic et al.
~\cite{smailagic1993case}~\cite{smailagic1998very}~\cite{smailagic2002application}
created prototypes of wearable computers to assist several cognitive tasks, for
example, displaying inspection manuals in a head-up screen to facilitate
aircraft maintenance. Around the same time, Loomis et
al.~\cite{loomis1998navigation}~\cite{loomis1994personal} explored using
computers carried in a backpack to help the blind navigate through auditory
cues. Davis et al.~\cite{davies1998developing}~\cite{cheverst2000developing}
developed a context-sensitive intelligent visitor guide leveraging hand-portable
multimedia systems. While these research work pioneered cognitive assistance and
its related fields, their robustness and functionality are limited by the
technologies of their time.

More recently, as underlying technologies experience significant advancement, a
new genre of applications, Wearable Cognitive Assistance
(WCA)~\cite{ha2014towards}~\cite{chen2018application}, has emerged that pushes
the boundaries of augmented cognition. WCA applications continuously process
data from body-worn sensors and provide just-in-time guidance to help a user
complete a specific task. For example, an IKEA Lamp
assistant~\cite{chen2018application} has been built to assist the assembly of a
table lamp. To use the application, a user wears a head-mounted smart glass that
continuously captures her actions and surroundings from a first-person
viewpoint. In real-time, the camera stream is analyzed to identify the state of
the assembly. Audiovisual instructions are generated based on the detected
state. The instructions either demonstrate a subsequent procedure or alert and
correct a mistake.

Since its conceptualization in 2004~\cite{Satya2004}, WCA has attracted many
research interests from both academia and industry. The building blocks for its
vision came into place by 2014, enabling the first implementation of this
concept in {\em Gabriel}~\cite{ha2014towards}. In 2017, Chen et
al~\cite{chen2017empirical} described a number of applications of this genre,
quantified their latency requirements, and profiled the end-to-end latencies of
their implementations. In late 2017, SEMATECH and DARPA jointly funded \$27.5
million of research on such applications~\cite{Oakley2018, Stokes2018}.  At the
Mobile World Congress in February 2018, wearable cognitive assistance was the
focus of an entire session~\cite{Ray2018}.  For AI-based military use cases,
this class of applications is the centerpiece of ``Battlefield
2.0''~\cite{Doffman2018}. By mid-2019, WCA was being viewed as a prime source of
``killer apps'' for edge computing~\cite{Satya2019b,Satya2019c}.


Different from previous research efforts, the design goals of WCA advance the
frontier of mobile computing in multiple aspects. First, wearable devices,
particularly head-mounted smart glasses, are used to reduce the discomfort
caused by carrying a bulky computation device. Users are freed from holding a
smartphone and therefore able to interact with the physical world using both
hands. The convenience of this interaction model comes at the cost of
constrained computation resources. The small form-factor of smart glasses
significantly limits their onboard computation capability due to size, cooling,
and battery life reasons. Second, placed at the center of computation is the
unstructured high-dimensional image and video data. Only these data types can
satisfy the need to extract rich semantic information to identify the progress
and mistakes a user makes. Furthermore, state-of-art computer vision algorithms
used to analyze image data are both compute-intensive and challenging to
develop. Third, many cognitive assistants give real-time feedback to users and
have stringent end-to-end latency requirements. An instruction that arrives too
late often provides no value and may even confuse or annoy users. This
latency-sensitivity further increases their high demands of system resource and
optimizations.

To meet the latency and the compute requirements, previous research leverages
edge computing and offloads computation to a cloudlet. A
cloudlet~\cite{satyanarayanan2009case} is a small data-center located at the
edge of the Internet, one wireless hop away from users. Researchers have
developed an application framework for wearable cognitive assistance, named
Gabriel, that leverages cloudlets, optimizes for end-to-end latency, and eases
application
development~\cite{chen2018application}~\cite{ha2014towards}~\cite{chen2017empirical}.
On top of Gabriel, several prototype applications have been built, such as
Ping-Pong Assistance, Lego Assistance, Sandwich Assistance, and Ikea Lamp
Assembly Assistance. Using these applications as benchmarks,
Chen et al.~\cite{chen2017empirical} presented empirical measurements detailing the latency
contributions of individual system components. Furthermore, a multi-algorithm
approach was proposed to reduce the latency of computer vision computation by
executing multiple algorithms in parallel and conditionally selecting a fast and
accurate algorithm for the near future.

While previous research has demonstrated the technical feasibility of wearable
cognitive assistants and meeting latency requirements, many practical concerns
have not been addressed. First, previous work operates the wireless networks and
cloudlets at low utilization in order to meet application latency. The economics
of practical deployment preclude operation at such low utilization. In contrast,
resources are often highly utilized and congested when serving many users. How
to efficiently scale Gabriel applications to a large number of users remains to
be answered. Second, previous work on the Gabriel framework reduces application
development efforts by managing client-server communication, network flow
control, and cognitive engine discovery. However, the framework does not address
the most time-consuming parts of creating a wearable cognitive assistance
application. Experience has shown that developing computer vision modules that
analyze video feeds is a time-consuming and painstaking process that requires
special expertise and involves rounds of trial and error. Developer tools that
alleviate the time and the expertise needed can greatly facilitate the creation
of these applications.


\section{Thesis Statement}

In this thesis, we address the problem of scaling wearable cognitive assistance.
Scalability here has a two-fold meaning. First, a scalable system should enable
the most associated clients with fixed amount of infrastructure and has ways to
serve more clients as resources increase. Second, we want to enable small
software team to quickly create, deploy, and manage these applications. 
Notably, we claim that:

\textbf{Two critical challenges to the widespread adoption of wearable cognitive
  assistance are 1) the need to operate cloudlets and wireless network at low
  utilization to achieve acceptable end-to-end latency 2) the level of specialized
  skills and the long development time needed to create new applications. These
  challenges can be effectively addressed through system optimizations,
  functional extensions, and the addition of new software development tools to
  the Gabriel platform.}


The main contributions of this thesis are as follows:
\begin{enumerate}
  \item{We propose application-agnostic and application-aware techniques 
  to reduce offered load from WCA mobile client when oversubscription occurs.}
  \item{We provide a profiling-based cloudlet resource allocation mechanism that
  takes into account 
  of applications' adapatation behaviors.}
  \item{We create a suite of development and deployment tools to reduce the time
  and lower the barrier of entry for WCA developments.}
\end{enumerate}

\section{Thesis Overview}

The remainder of this thesis is organized as follows.

\begin{itemize}
  \item{In Chapter~\ref{chapter: bandwidth}, we describe application-agnostic techniques to reduce bandwidth consumption.}
  \item{In Chapter~\ref{chapter: load}, we propose and evaluate 
  application-specific techniques to reduce offered load. 
  We demonstrate their effectiveness 
  with minimal impact on result latency.}
  \item{In Chapter~\ref{chapter: cloudlet}, 
  we present a resource management mechanisms that takes into the account of
  application adaptation characteristics to optimize system-wide aggregation
  metrics.}
  \item{In Chapter~\ref{chapter: dev}, 
  we introduce a suite of development tools for quick prototyping.
  }
  \item{In Chapter~\ref{chapter: deploy}, 
  we showcase a deployment system to facilitate 
  deploying WCAs on cloudlets.}
\end{itemize}