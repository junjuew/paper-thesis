\chapter{Cloudlet Resource Management for Graceful Degradation of Service}
\label{chapter: cloudlet}

In addition to workload reduction at the client as discussed in
Chapter~\ref{chapter: load}, another key aspect of adaptation lies in the
resource management of cloudlet resources. We argue that naive resource
management schemes using statistical multiplexing cannot satisfy the needs of
edge-native applications in oversubscribed edge scenarios. Needed are
intelligent mechanisms that takes account of application degradation behaviors.
In this chapter, we introduce and evaluate such an adaptation-centric cloudlet
resource management mechanism.

In Original Gabriel which relies on operating system level statistical
multiplexing for resource sharing, an increasing number of clients means less
resources for each client. This results in all clients and all applications
suffering from long response time. For wearable cognitive assistance, long
response time results in feedback delivered too late, which has significantly
decreased value. In a data-center setting, a cloud-native application, can
quickly scale-up or scale-out by acquiring additional resources (e.g.
instantiating more virtual machines). However, at the edge, since the total
amount of hardware resources is constrained, acquiring more resources in face of
a flash crowd is not possible. Instead, we make the observation that
applications behave differently when the amount of resources allocated to them
changes. We can leverage application adaptation characteristics to create a
judicious and intelligent resource allocation plan that prioritizes some
applications. In particular, we focus on mechanisms rather than policies. Our
mechanism in this chapter enables external allocation policies to divide
cloudlet resources taking account of adaptation characteristics, so that quality
of service can be maintained for some clients.



\input{cloudlet-resource-management-profile}
\input{cloudlet-resource-management-allocation}
\input{cloudlet-resource-management-eval}
\input{cloudlet-resource-management-related}

\section{Chapter Summary and Discussion}
\label{cloudlet: summary}

More than a decade ago, the emergence of cloud computing led to the
realization that applications had to be written in a certain way to
take full advantage of elasticity of the cloud.  This led to the
concept of ``cloud-native applications'' whose scale-out capabilities
are well matched to the cloud, as well as tools and techniques to
easily create such applications.

The emergence of edge computing leads to another inflection point in application
design.  As last two chapters have shown, edge-native applications have to be
written in a way that is very different from cloud-native applications if they
are to be scalable. We explore client workload reduction and server resource
allocation to manage application quality of service in the face of contention
for cloudlet resources. We demonstrate that our system is able to ensure that in
overloaded situations, a subset of users are still served with good quality of
service rather than equally sharing resources and missing latency requirements
for all.

% In particular, it leads to ``edge-native applications'' (e.g Wearable
% Cognitive Assistance) that are deeply dependent on attributes such as low
% latency or bandwidth scalability that can only be obtained at the edge. However,
% as last two chapters have shown, edge-native applications have to be written in
% a way that is very different from cloud-native applications if they are to be
% scalable.

% We show that cloud-native implementation strategies that focus primarily on
% dynamic scale-out are unlikely to be effective for scalability in edge
% computing.  Instead, wearable cognitive assistance need to adapt their network
% and cloudlet resource demand to system load.  As the total number of Tier-3
% devices associated with a cloudlet increases, the per-device network and
% cloudlet load has to decrease.  This is a fundamental difference between
% cloud-native and edge-native approaches to scalability. 
